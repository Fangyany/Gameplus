{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGameFormer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m num_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     17\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nuplan/lib/python3.9/site-packages/torch/cuda/__init__.py:350\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    348\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nuplan/lib/python3.9/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from GameFormer.predictor import GameFormer\n",
    "from torch.utils.data import DataLoader\n",
    "from GameFormer.train_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from GameFormer.predictor_modules import *\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "num_neighbors = 20\n",
    "batch_size = 32\n",
    "# set up data loaders\n",
    "train_path = '/data/fyy/GameFormer-Planner/nuplan/processed_data/train'\n",
    "train_files = [f for d in os.listdir(train_path) for f in glob.glob(os.path.join(train_path, d, \"*.npz\"))]\n",
    "train_set = DrivingData(train_files, num_neighbors)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "count = 0\n",
    "with tqdm(train_loader, desc=\"Training\", unit=\"batch\") as data_epoch:\n",
    "    for batch in data_epoch:\n",
    "        count += 1\n",
    "        if count == 2:\n",
    "            break\n",
    "        # prepare data\n",
    "        inputs = {\n",
    "            'ego_agent_past': batch[0].to('cuda'),\n",
    "            'neighbor_agents_past': batch[1].to('cuda'),\n",
    "            'map_lanes': batch[2].to('cuda'),\n",
    "            'map_crosswalks': batch[3].to('cuda'),\n",
    "            'route_lanes': batch[4].to('cuda')\n",
    "        }\n",
    "\n",
    "        ego_future = batch[5].to('cuda')\n",
    "        neighbors_future = batch[6].to('cuda')\n",
    "        neighbors_future_valid = torch.ne(neighbors_future[..., :2], 0)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 21, 21, 5])\n",
      "torch.Size([32, 21, 256])\n"
     ]
    }
   ],
   "source": [
    "ego = inputs['ego_agent_past']    \n",
    "neighbors = inputs['neighbor_agents_past']    \n",
    "actors = torch.cat([ego[:, None, :, :5], neighbors[..., :5]], dim=1)\n",
    "\n",
    "ego_encoder = AgentEncoder(agent_dim=7).cuda() \n",
    "encoded_ego = ego_encoder(ego)\n",
    "agent_encoder = AgentEncoder(agent_dim=11).cuda()\n",
    "encoded_neighbors = [agent_encoder(neighbors[:, i]) for i in range(neighbors.shape[1])]\n",
    "\n",
    "encoded_actors = torch.stack([encoded_ego] + encoded_neighbors, dim=1)  \n",
    "actors_mask = torch.eq(actors[:, :, -1].sum(-1), 0)\n",
    "\n",
    "# print(actors.shape)\n",
    "print(encoded_actors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 50, 7]) torch.Size([32, 10, 50, 3]) torch.Size([32, 5, 30, 3])\n"
     ]
    }
   ],
   "source": [
    "from GameFormer.predictor_modules import *\n",
    "_lane_len = 50\n",
    "_lane_feature = 7\n",
    "_route_len = 50\n",
    "_route_feature = 3\n",
    "\n",
    "nbr_lanes = inputs['map_lanes']\n",
    "route_lanes = inputs['route_lanes']\n",
    "crosswalk = inputs['map_crosswalks']\n",
    "print(nbr_lanes.shape, route_lanes.shape, crosswalk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1000, 256]) torch.Size([32, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LaneNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaneNet, self).__init__()\n",
    "        input_size = 7\n",
    "        output_size = 256\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)  \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)  \n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        self._lane_feature = 7\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(32, -1, self._lane_feature)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # pooling\n",
    "        x = x.transpose(1, 2) \n",
    "        x = F.avg_pool1d(x, kernel_size=2, stride=2)  \n",
    "        x = x.transpose(1, 2)  \n",
    "        \n",
    "        # 更新维度信息\n",
    "        _, seq_len, _ = x.size()  \n",
    "        x = x.view(-1, self._lane_feature).float()\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x) \n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x) \n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # 将x的形状重塑回 [32, 1000, 256]\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        mask = torch.eq(x[:, :, ::].sum(-1), 0)\n",
    "        return x, mask\n",
    "\n",
    "\n",
    "class RouteNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RouteNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64) \n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.linear = nn.Linear(128, 256)\n",
    "        self._route_len = 50\n",
    "        self._route_feature = 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(32, -1, self._route_feature)\n",
    "        # 输入形状: [32, 500, 3]\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) \n",
    "        x = F.relu(x)  \n",
    "        batch_size, channels, seq_len = x.shape\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x = x.contiguous().view(-1, channels)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        x = F.max_pool1d(x.permute(0, 2, 1), kernel_size=500, stride=500).permute(0, 2, 1)\n",
    "        return x\n",
    " \n",
    "    \n",
    "lanenet = LaneNet().cuda()\n",
    "routenet = RouteNet().cuda()\n",
    "\n",
    "encoded_lane, map_mask = lanenet(nbr_lanes)\n",
    "encoded_route = routenet(route_lanes)\n",
    "print(encoded_lane.shape, encoded_route.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1000, 256])\n"
     ]
    }
   ],
   "source": [
    "class M2M(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M2M, self).__init__()\n",
    "        self.linear1 = nn.Linear(512, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)  \n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)  \n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256) \n",
    "\n",
    "        # 初始化模型参数\n",
    "        for layer in [self.linear1, self.linear2, self.linear3]:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, lanes, route):\n",
    "        batch_size, num_lanes, len_feat = lanes.size()\n",
    "        \n",
    "        route_features = []\n",
    "        for i in range(batch_size):\n",
    "            route_feature = route[i].repeat(num_lanes, 1)\n",
    "            route_features.append(route_feature)\n",
    "\n",
    "        route_features = torch.cat(route_features, dim=0)\n",
    "        # print(route_features.shape, lanes.reshape(-1, len_feat).shape)\n",
    "        lanes_concat = torch.cat((lanes.reshape(-1, len_feat), route_features), dim=1)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.linear1(lanes_concat)))\n",
    "        x = F.relu(self.bn2(self.linear2(x)))\n",
    "        x = F.relu(self.bn3(self.linear3(x)))\n",
    "        x = x.reshape(batch_size, num_lanes, len_feat)\n",
    "        return x\n",
    "\n",
    "m2m = M2M().to(device)\n",
    "encoded_map = m2m(encoded_lane, encoded_route)\n",
    "print(encoded_map.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200, 256]) torch.Size([32, 50, 256])\n"
     ]
    }
   ],
   "source": [
    "# lane_encoder = VectorMapEncoder(_lane_feature, _lane_len).cuda()\n",
    "# encoded_nbr_lanes, nbr_lanes_mask = lane_encoder(nbr_lanes)\n",
    "\n",
    "# route_encoder = VectorMapEncoder(_route_feature, _route_len).cuda()\n",
    "# encoded_route_lanes, route_lanes_mask = route_encoder(route_lanes)\n",
    "\n",
    "# print(encoded_nbr_lanes.shape, encoded_route_lanes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention fusion encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1021, 256])\n"
     ]
    }
   ],
   "source": [
    "# shape = (32, 236, 256)\n",
    "input = torch.cat([encoded_actors, encoded_map], dim=1)\n",
    "mask = torch.cat([actors_mask, map_mask], dim=1)\n",
    "\n",
    "dim, layers, heads, dropout = 256, 6, 8, 0.1\n",
    "attention_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
    "                                                activation='gelu', dropout=dropout, batch_first=True)\n",
    "fusion_encoder = nn.TransformerEncoder(attention_layer, layers).cuda()\n",
    "encoding = fusion_encoder(input, src_key_padding_mask=mask)\n",
    "print(encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = {\n",
    "    'actors': actors,\n",
    "    'encoding': encoding,\n",
    "    'mask': mask,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 21, 21, 5])\n",
      "torch.Size([32, 1021, 256])\n",
      "torch.Size([32, 1021])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_outputs['actors'].shape)\n",
    "print(encoder_outputs['encoding'].shape)\n",
    "print(encoder_outputs['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 3]) torch.Size([32, 80, 60])\n",
      "torch.Size([32, 80, 63])\n"
     ]
    }
   ],
   "source": [
    "ego_future = batch[5].to('cuda')\n",
    "neighbors_future = batch[6].to('cuda')\n",
    "\n",
    "print(ego_future.unsqueeze(1).permute(0, 2, 1, 3).reshape(32, 80, -1).shape, neighbors_future.permute(0, 2, 1, 3).reshape(32, 80, -1).shape)\n",
    "fut_actors = torch.cat([ego_future.unsqueeze(1).permute(0, 2, 1, 3).reshape(32, 80, -1), \n",
    "                        neighbors_future.permute(0, 2, 1, 3).reshape(32, 80, -1)], dim=-1)\n",
    "print(fut_actors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 63]) torch.Size([32, 80, 3]) torch.Size([32, 1021, 256])\n"
     ]
    }
   ],
   "source": [
    "print(fut_actors.shape, ego_future.shape,encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 256]) torch.Size([32, 80, 63])\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, memory_dim, num_heads, hidden_dim, num_layers, output_dim):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.memory_embedding = nn.Linear(memory_dim, hidden_dim)\n",
    "        self.pos_encoder_tgt = PositionalEncoding(hidden_dim)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(hidden_dim, num_heads, hidden_dim)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, tgt, memory):\n",
    "        tgt = self.embedding(tgt)\n",
    "        memory = self.memory_embedding(memory)\n",
    "        tgt = self.pos_encoder_tgt(tgt)\n",
    "        # input is [sequence_length, batch_size, features]\n",
    "        tgt = tgt.permute(1, 0, 2)  \n",
    "        memory = memory.permute(1, 0, 2) \n",
    "        decoding = self.transformer_decoder(tgt, memory)\n",
    "        decoding = decoding.permute(1, 0, 2)  #  [batch_size, sequence_length, features]\n",
    "        output = self.fc(decoding)\n",
    "        return decoding, output\n",
    "\n",
    "decoder = TransformerDecoder(input_dim=63, memory_dim=256, num_heads=8, hidden_dim=256, num_layers=3, output_dim=63).to(device)\n",
    "\n",
    "decoding, output = decoder(fut_actors, encoding)\n",
    "print(decoding.shape, output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 3])\n"
     ]
    }
   ],
   "source": [
    "class Planner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Planner, self).__init__()\n",
    "        self._future_len = 80\n",
    "        self.route_fusion = CrossTransformer()\n",
    "        self.plan_decoder = nn.Sequential(nn.Linear(512, 256), nn.ELU(), nn.Dropout(0.1), nn.Linear(256, self._future_len*2))\n",
    "        self.route_encoder = VectorMapEncoder(3, 50)\n",
    "\n",
    "    def dynamics_layer(self, controls, initial_state):       \n",
    "        dt = 0.1 # discrete time period [s]\n",
    "        max_a = 5 # vehicle's accleration limits [m/s^2]\n",
    "        max_d = 0.5 # vehicle's steering limits [rad]\n",
    "        \n",
    "        vel_init = torch.hypot(initial_state[..., 3], initial_state[..., 4])\n",
    "        vel = vel_init[:, None] + torch.cumsum(controls[..., 0].clamp(-max_a, max_a) * dt, dim=-1)\n",
    "        vel = torch.clamp(vel, min=0)\n",
    "\n",
    "        yaw_rate = controls[..., 1].clamp(-max_d, max_d) * vel\n",
    "        yaw = initial_state[:, None, 2] + torch.cumsum(yaw_rate * dt, dim=-1)\n",
    "        pi = torch.tensor(math.pi)\n",
    "        yaw = torch.fmod(yaw, 2 * pi)\n",
    "        # yaw = torch.fmod(yaw, 2*torch.pi)\n",
    "\n",
    "        vel_x = vel * torch.cos(yaw)\n",
    "        vel_y = vel * torch.sin(yaw)\n",
    "\n",
    "        x = initial_state[:, None, 0] + torch.cumsum(vel_x * dt, dim=-1)\n",
    "        y = initial_state[:, None, 1] + torch.cumsum(vel_y * dt, dim=-1)\n",
    "\n",
    "        return torch.stack((x, y, yaw), dim=-1)\n",
    "\n",
    "    def forward(self, env_encoding, route_lanes, initial_state):\n",
    "        route_lanes, mask = self.route_encoder(route_lanes)\n",
    "        mask[:, 0] = False\n",
    "        route_encoding = self.route_fusion(env_encoding, route_lanes, route_lanes, mask)\n",
    "        env_route_encoding = torch.cat([env_encoding, route_encoding], dim=-1)\n",
    "        # dim0是最大值value，dim1是索引\n",
    "        env_route_encoding = torch.max(env_route_encoding, dim=1)[0] # max pooling over modalities\n",
    "        control = self.plan_decoder(env_route_encoding)\n",
    "        control = control.reshape(-1, self._future_len, 2)\n",
    "        plan = self.dynamics_layer(control, initial_state)\n",
    "        return plan\n",
    "\n",
    "initial_state = encoder_outputs['actors'][:, 0, -1]\n",
    "planner = Planner().to(device)\n",
    "ego_plan = planner(decoding, route_lanes, initial_state)\n",
    "\n",
    "print(ego_plan.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
